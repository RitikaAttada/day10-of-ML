## ğŸŒ± Day 10 of My Machine Learning Journey

Welcome to Day 10 of my ML journey!
Today I worked on **linear regression** using real-world datasets from **Kaggle** and trained multiple TensorFlow models inside **Jupyter Notebooks in VS Code**. I created modular functions that handle normalization, training, prediction, and visualization â€” making it easier to reuse and scale.

---

### ğŸ“˜ What I Learned

âœ… Using Jupyter Notebooks inside VS Code for ML workflows
âœ… Reading and preprocessing Kaggle datasets
---

### ğŸ“Š Simple Linear Regression Projects

1. ğŸ’¼ **Predict Salary from Experience**

   * **Source:** Kaggle
   * Inputs: Years of experience
   * Output: Salary in â‚¹
   * Insight: Linear upward trend in salary with experience

2. ğŸ§¾ **Predict Insurance Premium from Age**

   * **Source:** Self-curated
   * Inputs: Age
   * Output: Insurance premium in â‚¹
   * Observation: Premium increases consistently with age

3. ğŸ§  **Predict Exam Scores from Study Hours**

   * **Source:** Kaggle (Student Scores dataset)
   * Inputs: Hours studied
   * Output: Exam score (%)
   * Result: Model captured the positive correlation cleanly
---
### ğŸ“Œ Tools & Techniques Used

* ğŸ§  TensorFlow & Keras
* ğŸ§® NumPy, Pandas
* ğŸ“Š Matplotlib for visualization
* ğŸ““ Jupyter Notebook in VS Code
* ğŸ“ Datasets from Kaggle
* ğŸ”„ Data normalization & denormalization
* ğŸ’¾ Model saving & reloading (`.keras`)
* `reshape(-1, 1)` for training input formatting

---

### ğŸ§  Whatâ€™s Next?

Coming up:

ğŸ” Polynomial Regression for non-linear patterns
ğŸ” Logistic Regression for classification problems
ğŸ“Š Evaluation Metrics (MAE, MSE, RMSE)
ğŸ“‚ Scaling up with larger Kaggle datasets

---
